{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/electricity/train_df.csv')\n",
    "test_df = pd.read_csv('../../data/electricity/test_df.csv')\n",
    "X_train_df = pd.read_csv('../../data/electricity/y_train_df.csv')\n",
    "X_test_df = pd.read_csv('../../data/electricity/X_test_df.csv')\n",
    "y_train_df = pd.read_csv('../../data/electricity/y_train_df.csv')\n",
    "y_test_df = pd.read_csv('../../data/electricity/y_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_length = 24*7\n",
    "# target_seq_length = prediction_length\n",
    "# input_size = 1\n",
    "# hidden_size = 10\n",
    "# num_layers = 1\n",
    "# output_size = 1\n",
    "# learning_rate = 0.013\n",
    "# epochs = 800\n",
    "# batch_n = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_variable = test_df.drop(columns='datetime_utc').columns\n",
    "target_variable = 'price_de'\n",
    "timestemp_col = 'datetime_utc'\n",
    "step_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"seq_length\": 24 * 7,             # Sequence length\n",
    "    \"target_seq_length\": 24,          # Target sequence length for forecasting\n",
    "    \"input_size\": len(feature_variable), #1,                  # Input size\n",
    "    \"hidden_size\": 60,                # Hidden size of GRU\n",
    "    \"num_layers\": 5,                  # Number of layers in GRU\n",
    "    \"output_size\": len(feature_variable),                 # Output size\n",
    "    \"learning_rate\": 0.001,           # Learning rate\n",
    "    \"epochs\": 100,                    # Number of training epochs\n",
    "    \"batch_size\": 64,                 # Batch size\n",
    "    \"dropout\": 0.2                    # Dropout rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_data = scaler.fit_transform(data)#(data.reshape(-1, 1))\n",
    "    # scaled_data = scaled_data.flatten()\n",
    "\n",
    "    return scaled_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, seq_length, target_seq_length):\n",
    "\n",
    "    data = df.values\n",
    "    data, scaler = normalize_data(data)\n",
    "    X, Y = [], []\n",
    "    sequences_dict = {}\n",
    "\n",
    "    # price_de_idx = df.columns.get_loc('price_de')\n",
    "\n",
    "    for i in range(len(data) - seq_length - target_seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length]\n",
    "        # y = data[(i + seq_length):(i + seq_length+target_seq_length)]\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "    sequences_dict = {'X' : np.array(X), 'y': np.array(Y), 'scaler' : scaler}\n",
    "\n",
    "    return sequences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sequence(df, unique_id, seq_length):\n",
    "#     # Xs, Ys = [], []\n",
    "#     sequence_dict = {}\n",
    "#     grouped = df.groupby(unique_id)\n",
    "\n",
    "#     for group_id, group in grouped:\n",
    "#         data = group['y'].values\n",
    "#         data, scaler = normalize_data(data)\n",
    "#         X, Y = [], []\n",
    "#         for i in range(len(data) - seq_length):\n",
    "#             X.append(data[i:(i + seq_length)])\n",
    "#             Y.append(data[i + seq_length])\n",
    "#         sequence_dict[group_id] = {'X' : np.array(X), 'y': np.array(Y), 'scaler' : scaler}\n",
    "\n",
    "#     return sequence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        gru_out, _ = self.gru(x, h0)\n",
    "        out = self.fc(gru_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "\n",
    "    Args:\n",
    "    y_true (torch.Tensor): The true values.\n",
    "    y_pred (torch.Tensor): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The SMAPE value.\n",
    "    \"\"\"\n",
    "    epsilon = torch.finfo(y_true.dtype).eps\n",
    "    denominator = torch.max(torch.abs(y_true) + torch.abs(y_pred) + epsilon, torch.tensor(0.5 + epsilon).to(y_true.device))\n",
    "\n",
    "    diff = 2 * torch.abs(y_pred - y_true) / denominator\n",
    "    smape_value = 100 / len(y_true) * torch.sum(diff)\n",
    "    return smape_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                X_train, \n",
    "                y_train, \n",
    "                batch_size,\n",
    "                epochs):\n",
    "    \n",
    "    dataset = TensorDataset(X_train, y_train)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (sequences, targets) in enumerate(data_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(sequences)\n",
    "            loss = criterion(pred, targets.squeeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    # generating forecasts\n",
    "    model.eval()\n",
    "    last_sequence = X_train[-1:].to(device) # [1, 168, 16]\n",
    "    # with torch.no_grad():\n",
    "    #     forecast_seq = model(last_sequence) \n",
    "\n",
    "\n",
    "    forecast_seq = torch.Tensor().to(device)\n",
    "    \n",
    "    for _ in range(hyperparameters[\"target_seq_length\"]):\n",
    "        with torch.no_grad():\n",
    "            next_step_forecast = model(last_sequence) # [1, 16]\n",
    "            # print(next_step_forecast.size()) # [1, 16]\n",
    "            # print(next_step_forecast[:, -1:].size()) # [1, 1]\n",
    "            # print(next_step_forecast.unsqueeze(-1).size()) # [1, 16, 1]\n",
    "            # print(next_step_forecast.unsqueeze(1).size()) # [1, 1, 16]\n",
    "            # break\n",
    "            # forecast_seq = torch.cat((forecast_seq, next_step_forecast[:, -1:]), dim=1)\n",
    "            forecast_seq = torch.cat((forecast_seq, next_step_forecast), dim=0) # [1, 16, 1]\n",
    "            # print(forecast_seq.size())\n",
    "            # break\n",
    "            last_sequence = torch.cat((last_sequence[:, 1:, :], next_step_forecast.unsqueeze(1)), dim=1)\n",
    "    \n",
    "    return model, forecast_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data slices to generate forecasts for the next 8 days\n",
    "index_cutoffs = [24*i for i in range(7, -1, -1)]\n",
    "train_df_list = [train_df.iloc[:-idx] if idx != 0 else train_df for idx in index_cutoffs]\n",
    "index_ceiling = [x.index.stop for x in train_df_list]\n",
    "test_df_list = [train_df['price_de'].iloc[idx:idx+step_size] if idx!=index_ceiling[-1] else test_df['price_de'] for idx in index_ceiling]\n",
    "y_hat_full = np.empty((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dict = create_sequences(train_df[feature_variable], hyperparameters[\"seq_length\"], hyperparameters[\"target_seq_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([64, 1, 16])) that is different to the input size (torch.Size([64, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([38, 1, 16])) that is different to the input size (torch.Size([38, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 0.06142239272594452\n",
      "Epoch [2/250], Loss: 0.0611252561211586\n",
      "Epoch [3/250], Loss: 0.06729058921337128\n",
      "Epoch [4/250], Loss: 0.06908556073904037\n",
      "Epoch [5/250], Loss: 0.06151284649968147\n",
      "Epoch [6/250], Loss: 0.04959110543131828\n",
      "Epoch [7/250], Loss: 0.05036606639623642\n",
      "Epoch [8/250], Loss: 0.049042873084545135\n",
      "Epoch [9/250], Loss: 0.045563697814941406\n",
      "Epoch [10/250], Loss: 0.04647109657526016\n",
      "Epoch [11/250], Loss: 0.04457663744688034\n",
      "Epoch [12/250], Loss: 0.044874001294374466\n",
      "Epoch [13/250], Loss: 0.04588751867413521\n",
      "Epoch [14/250], Loss: 0.042978931218385696\n",
      "Epoch [15/250], Loss: 0.04551471397280693\n",
      "Epoch [16/250], Loss: 0.041095953434705734\n",
      "Epoch [17/250], Loss: 0.041370365768671036\n",
      "Epoch [18/250], Loss: 0.04133692383766174\n",
      "Epoch [19/250], Loss: 0.03860574960708618\n",
      "Epoch [20/250], Loss: 0.03933161497116089\n",
      "Epoch [21/250], Loss: 0.03860257938504219\n",
      "Epoch [22/250], Loss: 0.03780432417988777\n",
      "Epoch [23/250], Loss: 0.03769420459866524\n",
      "Epoch [24/250], Loss: 0.03748597204685211\n",
      "Epoch [25/250], Loss: 0.036676425486803055\n",
      "Epoch [26/250], Loss: 0.03578244149684906\n",
      "Epoch [27/250], Loss: 0.036804355680942535\n",
      "Epoch [28/250], Loss: 0.035399384796619415\n",
      "Epoch [29/250], Loss: 0.0351574532687664\n",
      "Epoch [30/250], Loss: 0.03398199751973152\n",
      "Epoch [31/250], Loss: 0.034902624785900116\n",
      "Epoch [32/250], Loss: 0.038131650537252426\n",
      "Epoch [33/250], Loss: 0.03840107470750809\n",
      "Epoch [34/250], Loss: 0.037246886640787125\n",
      "Epoch [35/250], Loss: 0.03663074970245361\n",
      "Epoch [36/250], Loss: 0.03503616526722908\n",
      "Epoch [37/250], Loss: 0.03594052791595459\n",
      "Epoch [38/250], Loss: 0.03658101707696915\n",
      "Epoch [39/250], Loss: 0.03506488725543022\n",
      "Epoch [40/250], Loss: 0.04112491384148598\n",
      "Epoch [41/250], Loss: 0.03529106453061104\n",
      "Epoch [42/250], Loss: 0.036202285438776016\n",
      "Epoch [43/250], Loss: 0.03611386567354202\n",
      "Epoch [44/250], Loss: 0.03542380779981613\n",
      "Epoch [45/250], Loss: 0.03779172897338867\n",
      "Epoch [46/250], Loss: 0.03653320297598839\n",
      "Epoch [47/250], Loss: 0.03454461693763733\n",
      "Epoch [48/250], Loss: 0.03499889373779297\n",
      "Epoch [49/250], Loss: 0.0353231355547905\n",
      "Epoch [50/250], Loss: 0.0354476161301136\n",
      "Epoch [51/250], Loss: 0.03795617073774338\n",
      "Epoch [52/250], Loss: 0.03450265899300575\n",
      "Epoch [53/250], Loss: 0.03687058016657829\n",
      "Epoch [54/250], Loss: 0.03580344468355179\n",
      "Epoch [55/250], Loss: 0.03595605865120888\n",
      "Epoch [56/250], Loss: 0.03470906242728233\n",
      "Epoch [57/250], Loss: 0.03490660339593887\n",
      "Epoch [58/250], Loss: 0.03775881230831146\n",
      "Epoch [59/250], Loss: 0.034757450222969055\n",
      "Epoch [60/250], Loss: 0.03727021813392639\n",
      "Epoch [61/250], Loss: 0.0365569181740284\n",
      "Epoch [62/250], Loss: 0.03637583181262016\n",
      "Epoch [63/250], Loss: 0.036307722330093384\n",
      "Epoch [64/250], Loss: 0.038983918726444244\n",
      "Epoch [65/250], Loss: 0.03682243078947067\n",
      "Epoch [66/250], Loss: 0.03649343177676201\n",
      "Epoch [67/250], Loss: 0.03584282472729683\n",
      "Epoch [68/250], Loss: 0.03709489852190018\n",
      "Epoch [69/250], Loss: 0.03427708148956299\n",
      "Epoch [70/250], Loss: 0.037311747670173645\n",
      "Epoch [71/250], Loss: 0.03535957634449005\n",
      "Epoch [72/250], Loss: 0.035506803542375565\n",
      "Epoch [73/250], Loss: 0.03420965373516083\n",
      "Epoch [74/250], Loss: 0.034260813146829605\n",
      "Epoch [75/250], Loss: 0.035011570900678635\n",
      "Epoch [76/250], Loss: 0.036157600581645966\n",
      "Epoch [77/250], Loss: 0.0371040403842926\n",
      "Epoch [78/250], Loss: 0.03362142667174339\n",
      "Epoch [79/250], Loss: 0.03389007970690727\n",
      "Epoch [80/250], Loss: 0.034990329295396805\n",
      "Epoch [81/250], Loss: 0.035472191870212555\n",
      "Epoch [82/250], Loss: 0.034682102501392365\n",
      "Epoch [83/250], Loss: 0.03453896939754486\n",
      "Epoch [84/250], Loss: 0.03641088679432869\n",
      "Epoch [85/250], Loss: 0.03387882560491562\n",
      "Epoch [86/250], Loss: 0.03366534784436226\n",
      "Epoch [87/250], Loss: 0.03354119881987572\n",
      "Epoch [88/250], Loss: 0.03417711332440376\n",
      "Epoch [89/250], Loss: 0.04039270803332329\n",
      "Epoch [90/250], Loss: 0.03482652083039284\n",
      "Epoch [91/250], Loss: 0.035169269889593124\n",
      "Epoch [92/250], Loss: 0.034191060811281204\n",
      "Epoch [93/250], Loss: 0.033315591514110565\n",
      "Epoch [94/250], Loss: 0.03473434969782829\n",
      "Epoch [95/250], Loss: 0.03424627706408501\n",
      "Epoch [96/250], Loss: 0.034790534526109695\n",
      "Epoch [97/250], Loss: 0.03337547183036804\n",
      "Epoch [98/250], Loss: 0.03516271710395813\n",
      "Epoch [99/250], Loss: 0.033495333045721054\n",
      "Epoch [100/250], Loss: 0.036143574863672256\n",
      "Epoch [101/250], Loss: 0.035178180783987045\n",
      "Epoch [102/250], Loss: 0.034477170556783676\n",
      "Epoch [103/250], Loss: 0.03375731036067009\n",
      "Epoch [104/250], Loss: 0.03470386937260628\n",
      "Epoch [105/250], Loss: 0.03432288393378258\n",
      "Epoch [106/250], Loss: 0.03648783639073372\n",
      "Epoch [107/250], Loss: 0.033207036554813385\n",
      "Epoch [108/250], Loss: 0.035714179277420044\n",
      "Epoch [109/250], Loss: 0.03469717130064964\n",
      "Epoch [110/250], Loss: 0.034789077937603\n",
      "Epoch [111/250], Loss: 0.03423543646931648\n",
      "Epoch [112/250], Loss: 0.033434826880693436\n",
      "Epoch [113/250], Loss: 0.035619333386421204\n",
      "Epoch [114/250], Loss: 0.03303047642111778\n",
      "Epoch [115/250], Loss: 0.035927701741456985\n",
      "Epoch [116/250], Loss: 0.03372204303741455\n",
      "Epoch [117/250], Loss: 0.03777085244655609\n",
      "Epoch [118/250], Loss: 0.039663054049015045\n",
      "Epoch [119/250], Loss: 0.033816833049058914\n",
      "Epoch [120/250], Loss: 0.03415902331471443\n",
      "Epoch [121/250], Loss: 0.03520243242383003\n",
      "Epoch [122/250], Loss: 0.03440757468342781\n",
      "Epoch [123/250], Loss: 0.034579936414957047\n",
      "Epoch [124/250], Loss: 0.03460683673620224\n",
      "Epoch [125/250], Loss: 0.03455924987792969\n",
      "Epoch [126/250], Loss: 0.034185200929641724\n",
      "Epoch [127/250], Loss: 0.036038607358932495\n",
      "Epoch [128/250], Loss: 0.033527884632349014\n",
      "Epoch [129/250], Loss: 0.03324086591601372\n",
      "Epoch [130/250], Loss: 0.03313860297203064\n",
      "Epoch [131/250], Loss: 0.034797534346580505\n",
      "Epoch [132/250], Loss: 0.03371315076947212\n",
      "Epoch [133/250], Loss: 0.03253249078989029\n",
      "Epoch [134/250], Loss: 0.03458913415670395\n",
      "Epoch [135/250], Loss: 0.032773103564977646\n",
      "Epoch [136/250], Loss: 0.03303755819797516\n",
      "Epoch [137/250], Loss: 0.033945146948099136\n",
      "Epoch [138/250], Loss: 0.03426254913210869\n",
      "Epoch [139/250], Loss: 0.035092953592538834\n",
      "Epoch [140/250], Loss: 0.03528575599193573\n",
      "Epoch [141/250], Loss: 0.03411711007356644\n",
      "Epoch [142/250], Loss: 0.03384679928421974\n",
      "Epoch [143/250], Loss: 0.03319995477795601\n",
      "Epoch [144/250], Loss: 0.032908085733652115\n",
      "Epoch [145/250], Loss: 0.03300744295120239\n",
      "Epoch [146/250], Loss: 0.03543073311448097\n",
      "Epoch [147/250], Loss: 0.033772751688957214\n",
      "Epoch [148/250], Loss: 0.034341324120759964\n",
      "Epoch [149/250], Loss: 0.03403972089290619\n",
      "Epoch [150/250], Loss: 0.03423730656504631\n",
      "Epoch [151/250], Loss: 0.033993035554885864\n",
      "Epoch [152/250], Loss: 0.03325493261218071\n",
      "Epoch [153/250], Loss: 0.03290744125843048\n",
      "Epoch [154/250], Loss: 0.03321514278650284\n",
      "Epoch [155/250], Loss: 0.033325742930173874\n",
      "Epoch [156/250], Loss: 0.035278741270303726\n",
      "Epoch [157/250], Loss: 0.03436140716075897\n",
      "Epoch [158/250], Loss: 0.03388896957039833\n",
      "Epoch [159/250], Loss: 0.0336160771548748\n",
      "Epoch [160/250], Loss: 0.03464679792523384\n",
      "Epoch [161/250], Loss: 0.03370050713419914\n",
      "Epoch [162/250], Loss: 0.0330871045589447\n",
      "Epoch [163/250], Loss: 0.03342421352863312\n",
      "Epoch [164/250], Loss: 0.033654212951660156\n",
      "Epoch [165/250], Loss: 0.03275206685066223\n",
      "Epoch [166/250], Loss: 0.03474294766783714\n",
      "Epoch [167/250], Loss: 0.03333364799618721\n",
      "Epoch [168/250], Loss: 0.03499070182442665\n",
      "Epoch [169/250], Loss: 0.03307224437594414\n",
      "Epoch [170/250], Loss: 0.03258732706308365\n",
      "Epoch [171/250], Loss: 0.03449813276529312\n",
      "Epoch [172/250], Loss: 0.033561479300260544\n",
      "Epoch [173/250], Loss: 0.03293684870004654\n",
      "Epoch [174/250], Loss: 0.033821478486061096\n",
      "Epoch [175/250], Loss: 0.03436092287302017\n",
      "Epoch [176/250], Loss: 0.0330585353076458\n",
      "Epoch [177/250], Loss: 0.03375865891575813\n",
      "Epoch [178/250], Loss: 0.03325631469488144\n",
      "Epoch [179/250], Loss: 0.033698588609695435\n",
      "Epoch [180/250], Loss: 0.03398958593606949\n",
      "Epoch [181/250], Loss: 0.0343143567442894\n",
      "Epoch [182/250], Loss: 0.033404383808374405\n",
      "Epoch [183/250], Loss: 0.03384559974074364\n",
      "Epoch [184/250], Loss: 0.03313053771853447\n",
      "Epoch [185/250], Loss: 0.03333640098571777\n",
      "Epoch [186/250], Loss: 0.032888263463974\n",
      "Epoch [187/250], Loss: 0.03444766253232956\n",
      "Epoch [188/250], Loss: 0.03414056450128555\n",
      "Epoch [189/250], Loss: 0.033049002289772034\n",
      "Epoch [190/250], Loss: 0.03435521200299263\n",
      "Epoch [191/250], Loss: 0.035543181002140045\n",
      "Epoch [192/250], Loss: 0.032989501953125\n",
      "Epoch [193/250], Loss: 0.03466709703207016\n",
      "Epoch [194/250], Loss: 0.032540515065193176\n",
      "Epoch [195/250], Loss: 0.03290838748216629\n",
      "Epoch [196/250], Loss: 0.03405690938234329\n",
      "Epoch [197/250], Loss: 0.034197404980659485\n",
      "Epoch [198/250], Loss: 0.032446958124637604\n",
      "Epoch [199/250], Loss: 0.033012598752975464\n",
      "Epoch [200/250], Loss: 0.03496376425027847\n",
      "Epoch [201/250], Loss: 0.0337333083152771\n",
      "Epoch [202/250], Loss: 0.034985315054655075\n",
      "Epoch [203/250], Loss: 0.03308379277586937\n",
      "Epoch [204/250], Loss: 0.03339974582195282\n",
      "Epoch [205/250], Loss: 0.03430626541376114\n",
      "Epoch [206/250], Loss: 0.03352127969264984\n",
      "Epoch [207/250], Loss: 0.03283577039837837\n",
      "Epoch [208/250], Loss: 0.032368868589401245\n",
      "Epoch [209/250], Loss: 0.032105445861816406\n",
      "Epoch [210/250], Loss: 0.03352256119251251\n",
      "Epoch [211/250], Loss: 0.03312265872955322\n",
      "Epoch [212/250], Loss: 0.03245146945118904\n",
      "Epoch [213/250], Loss: 0.03325982019305229\n",
      "Epoch [214/250], Loss: 0.03363518416881561\n",
      "Epoch [215/250], Loss: 0.03327382355928421\n",
      "Epoch [216/250], Loss: 0.03354811295866966\n",
      "Epoch [217/250], Loss: 0.03303486108779907\n",
      "Epoch [218/250], Loss: 0.03391148895025253\n",
      "Epoch [219/250], Loss: 0.033012572675943375\n",
      "Epoch [220/250], Loss: 0.03353484347462654\n",
      "Epoch [221/250], Loss: 0.03295927494764328\n",
      "Epoch [222/250], Loss: 0.03259790688753128\n",
      "Epoch [223/250], Loss: 0.033757127821445465\n",
      "Epoch [224/250], Loss: 0.0335688479244709\n",
      "Epoch [225/250], Loss: 0.03272951766848564\n",
      "Epoch [226/250], Loss: 0.032350778579711914\n",
      "Epoch [227/250], Loss: 0.03427159786224365\n",
      "Epoch [228/250], Loss: 0.032263919711112976\n",
      "Epoch [229/250], Loss: 0.032420117408037186\n",
      "Epoch [230/250], Loss: 0.035043325275182724\n",
      "Epoch [231/250], Loss: 0.03311682492494583\n",
      "Epoch [232/250], Loss: 0.032830413430929184\n",
      "Epoch [233/250], Loss: 0.03403271362185478\n",
      "Epoch [234/250], Loss: 0.03369871899485588\n",
      "Epoch [235/250], Loss: 0.03270784392952919\n",
      "Epoch [236/250], Loss: 0.03259938582777977\n",
      "Epoch [237/250], Loss: 0.033017102628946304\n",
      "Epoch [238/250], Loss: 0.03360896185040474\n",
      "Epoch [239/250], Loss: 0.033332034945487976\n",
      "Epoch [240/250], Loss: 0.03320080414414406\n",
      "Epoch [241/250], Loss: 0.03300800919532776\n",
      "Epoch [242/250], Loss: 0.03307797759771347\n",
      "Epoch [243/250], Loss: 0.03226712346076965\n",
      "Epoch [244/250], Loss: 0.03264196217060089\n",
      "Epoch [245/250], Loss: 0.033734340220689774\n",
      "Epoch [246/250], Loss: 0.03381321206688881\n",
      "Epoch [247/250], Loss: 0.032475318759679794\n",
      "Epoch [248/250], Loss: 0.03306762874126434\n",
      "Epoch [249/250], Loss: 0.033469799906015396\n",
      "Epoch [250/250], Loss: 0.03423892706632614\n"
     ]
    }
   ],
   "source": [
    "# y_hat_df_gru = test_data.copy().rename(columns={'y' : 'y_hat'})\n",
    "# y_hat_df_gru['y_hat'] = pd.Series(dtype='float64')\n",
    "\n",
    "all_forecast_seq_descaled = []\n",
    "\n",
    "X_train = torch.from_numpy(sequences_dict['X'].astype(np.float32))#.unsqueeze(-1)\n",
    "y_train = torch.from_numpy(sequences_dict['y'].astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "model = GRU_Model(hyperparameters['input_size'], hyperparameters['hidden_size'], hyperparameters['num_layers'], hyperparameters['output_size'], hyperparameters['dropout'])\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = smape_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['learning_rate'])\n",
    "\n",
    "model_gru, forecast_seq = train_model(model,\n",
    "                                    criterion=criterion,\n",
    "                                    optimizer=optimizer,\n",
    "                                    X_train=X_train,\n",
    "                                    y_train=y_train,\n",
    "                                    batch_size=hyperparameters['batch_size'],\n",
    "                                    epochs=hyperparameters['epochs'])\n",
    "\n",
    "forecast_seq_descaled = sequences_dict['scaler'].inverse_transform(forecast_seq.cpu().numpy())\n",
    "# all_forecast_seq_descaled = np.hstack(all_forecast_seq_descaled, forecast_seq_descaled)\n",
    "# all_forecast_seq_descaled.append(forecast_seq_descaled)\n",
    "\n",
    "# all_forecast_seq_descaled = np.hstack(all_forecast_seq_descaled)\n",
    "\n",
    "# y_hat_df_gru['y_hat'] = all_forecast_seq_descaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 16)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_seq.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([84.739   , 84.565956, 84.22186 , 83.99491 , 83.97682 , 84.1916  ,\n",
       "       84.98759 , 87.22561 , 89.94887 , 91.17782 , 91.51087 , 91.55625 ,\n",
       "       91.51024 , 91.38597 , 90.81423 , 89.68096 , 88.58993 , 87.585304,\n",
       "       86.908226, 85.51874 , 82.99952 , 80.14192 , 76.78395 , 74.68101 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_seq_descaled[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87.3 ,  85.89,  85.88,  83.21,  82.71,  85.44,  86.3 ,  88.  ,\n",
       "        92.  ,  94.89,  91.28,  90.22,  87.94,  87.8 ,  91.5 , 102.87,\n",
       "       115.72, 127.98, 135.76, 124.47, 113.51, 102.58,  92.38,  87.41])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = smape_loss(torch.from_numpy(forecast_seq_descaled[:,-1]), torch.from_numpy(test_df.iloc[:,-1].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.583248978055664"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    seed_value = 42\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "    # Hyperparameters to tune\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 5, 50, step=5)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 10)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    # epochs = trial.suggest_int(\"epochs\", 100, 1000)\n",
    "\n",
    "    X_train = torch.from_numpy(sequences_dict['X'].astype(np.float32))#.unsqueeze(-1)\n",
    "    y_train = torch.from_numpy(sequences_dict['y'].astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "    model = GRU_Model(hyperparameters['input_size'], hidden_size, num_layers, hyperparameters['output_size'], dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model_gru, forecast_seq = train_model(model,\n",
    "                                        criterion=criterion,\n",
    "                                        optimizer=optimizer,\n",
    "                                        X_train=X_train,\n",
    "                                        y_train=y_train,\n",
    "                                        batch_size=batch_size,\n",
    "                                        epochs=hyperparameters['epochs'])\n",
    "\n",
    "    forecast_seq_descaled = sequences_dict['scaler'].inverse_transform(forecast_seq.cpu().numpy())\n",
    "\n",
    "    loss = smape_loss(torch.from_numpy(forecast_seq_descaled[:,-1]), torch.from_numpy(test_df.iloc[:,-1].values))\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:37:28,459] A new study created in memory with name: no-name-7bb74874-9a25-4338-9789-40e3d79e2ebd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 0.0867677852511406\n",
      "Epoch [40/100], Loss: 0.06007111072540283\n",
      "Epoch [60/100], Loss: 0.05978955700993538\n",
      "Epoch [80/100], Loss: 0.05940881744027138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:38:48,015] Trial 0 finished with value: 11.126343586501196 and parameters: {'learning_rate': 0.004006674501117757, 'hidden_size': 10, 'num_layers': 7, 'batch_size': 64, 'dropout': 0.45042215855549683}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.054651737213134766\n",
      "Epoch [20/100], Loss: 0.09155221283435822\n",
      "Epoch [40/100], Loss: 0.07811836153268814\n",
      "Epoch [60/100], Loss: 0.06711537390947342\n",
      "Epoch [80/100], Loss: 0.05931456759572029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:41:17,734] Trial 1 finished with value: 20.828225049722935 and parameters: {'learning_rate': 0.002548827108170144, 'hidden_size': 40, 'num_layers': 10, 'batch_size': 128, 'dropout': 0.39743585913612256}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.05385013669729233\n",
      "Epoch [20/100], Loss: 0.017406297847628593\n",
      "Epoch [40/100], Loss: 0.011404613964259624\n",
      "Epoch [60/100], Loss: 0.00820804014801979\n",
      "Epoch [80/100], Loss: 0.00761644309386611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:43:55,029] Trial 2 finished with value: 132.2431008602678 and parameters: {'learning_rate': 0.0006779460991653283, 'hidden_size': 20, 'num_layers': 8, 'batch_size': 32, 'dropout': 0.29298957616549914}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.009276356548070908\n",
      "Epoch [20/100], Loss: 0.025515267625451088\n",
      "Epoch [40/100], Loss: 0.02062283828854561\n",
      "Epoch [60/100], Loss: 0.016243500635027885\n",
      "Epoch [80/100], Loss: 0.01464024093002081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:45:23,322] Trial 3 finished with value: 91.63723154653412 and parameters: {'learning_rate': 0.00022306742134387437, 'hidden_size': 35, 'num_layers': 6, 'batch_size': 128, 'dropout': 0.18195523348668183}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.010686234571039677\n",
      "Epoch [20/100], Loss: 0.0037886607460677624\n",
      "Epoch [40/100], Loss: 0.0033743176609277725\n",
      "Epoch [60/100], Loss: 0.0024595262948423624\n",
      "Epoch [80/100], Loss: 0.0021341638639569283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:47:10,038] Trial 4 finished with value: 40.08491299666899 and parameters: {'learning_rate': 0.00028353462770069914, 'hidden_size': 25, 'num_layers': 2, 'batch_size': 32, 'dropout': 0.1384879090405875}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0018128203228116035\n",
      "Epoch [20/100], Loss: 0.07577995210886002\n",
      "Epoch [40/100], Loss: 0.08135593682527542\n",
      "Epoch [60/100], Loss: 0.08919282257556915\n",
      "Epoch [80/100], Loss: 0.09299831837415695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:47:57,044] Trial 5 finished with value: 20.344153024699573 and parameters: {'learning_rate': 0.006676158644850267, 'hidden_size': 15, 'num_layers': 7, 'batch_size': 128, 'dropout': 0.35567611817589917}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.08754562586545944\n",
      "Epoch [20/100], Loss: 0.03002062998712063\n",
      "Epoch [40/100], Loss: 0.044361092150211334\n",
      "Epoch [60/100], Loss: 0.06052280589938164\n",
      "Epoch [80/100], Loss: 0.03930492699146271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:51:15,209] Trial 6 finished with value: 20.724087159989768 and parameters: {'learning_rate': 0.0012860845591615977, 'hidden_size': 40, 'num_layers': 10, 'batch_size': 32, 'dropout': 0.21328516071511203}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.028967274352908134\n",
      "Epoch [20/100], Loss: 0.033728644251823425\n",
      "Epoch [40/100], Loss: 0.023362979292869568\n",
      "Epoch [60/100], Loss: 0.021399369463324547\n",
      "Epoch [80/100], Loss: 0.01846548542380333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:52:29,811] Trial 7 finished with value: 95.32590341372776 and parameters: {'learning_rate': 0.0068919185824332495, 'hidden_size': 15, 'num_layers': 6, 'batch_size': 64, 'dropout': 0.3480872857266776}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.01776016131043434\n",
      "Epoch [20/100], Loss: 0.011517936363816261\n",
      "Epoch [40/100], Loss: 0.009943433105945587\n",
      "Epoch [60/100], Loss: 0.008007503114640713\n",
      "Epoch [80/100], Loss: 0.007846965454518795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:53:25,155] Trial 8 finished with value: 30.708906525902744 and parameters: {'learning_rate': 0.0006189093178816213, 'hidden_size': 45, 'num_layers': 3, 'batch_size': 128, 'dropout': 0.4348504540175179}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0064843930304050446\n",
      "Epoch [20/100], Loss: 0.05045502260327339\n",
      "Epoch [40/100], Loss: 0.022689100354909897\n",
      "Epoch [60/100], Loss: 0.019704649224877357\n",
      "Epoch [80/100], Loss: 0.01931837759912014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:56:26,965] Trial 9 finished with value: 74.37339802831114 and parameters: {'learning_rate': 0.0001939449624483117, 'hidden_size': 40, 'num_layers': 10, 'batch_size': 64, 'dropout': 0.21721558213059378}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.01765473000705242\n",
      "Epoch [20/100], Loss: 0.06045743077993393\n",
      "Epoch [40/100], Loss: 0.050409115850925446\n",
      "Epoch [60/100], Loss: 0.05022186040878296\n",
      "Epoch [80/100], Loss: 0.04827507585287094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:57:36,215] Trial 10 finished with value: 19.13656602338714 and parameters: {'learning_rate': 0.03896500204512589, 'hidden_size': 10, 'num_layers': 4, 'batch_size': 64, 'dropout': 0.4857019170551138}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.04959206283092499\n",
      "Epoch [20/100], Loss: 0.07098069787025452\n",
      "Epoch [40/100], Loss: 0.05111311376094818\n",
      "Epoch [60/100], Loss: 0.057478565722703934\n",
      "Epoch [80/100], Loss: 0.07120084017515182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:58:45,136] Trial 11 finished with value: 28.315548198068402 and parameters: {'learning_rate': 0.05429067799286113, 'hidden_size': 5, 'num_layers': 4, 'batch_size': 64, 'dropout': 0.4993710604732742}. Best is trial 0 with value: 11.126343586501196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.07122325897216797\n",
      "Epoch [20/100], Loss: 0.049553144723176956\n",
      "Epoch [40/100], Loss: 0.05020619556307793\n",
      "Epoch [60/100], Loss: 0.04727892577648163\n",
      "Epoch [80/100], Loss: 0.0654643103480339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 18:59:52,519] Trial 12 finished with value: 10.857660870896238 and parameters: {'learning_rate': 0.045411478943589066, 'hidden_size': 5, 'num_layers': 4, 'batch_size': 64, 'dropout': 0.49852938147935916}. Best is trial 12 with value: 10.857660870896238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.05122563987970352\n",
      "Epoch [20/100], Loss: 0.10791610181331635\n",
      "Epoch [40/100], Loss: 0.06209280714392662\n",
      "Epoch [60/100], Loss: 0.06322503089904785\n",
      "Epoch [80/100], Loss: 0.06213310733437538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:01:00,443] Trial 13 finished with value: 11.211921520212861 and parameters: {'learning_rate': 0.018827759065772862, 'hidden_size': 5, 'num_layers': 5, 'batch_size': 64, 'dropout': 0.4486868152310195}. Best is trial 12 with value: 10.857660870896238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.06289715319871902\n",
      "Epoch [20/100], Loss: 0.06381219625473022\n",
      "Epoch [40/100], Loss: 0.06386886537075043\n",
      "Epoch [60/100], Loss: 0.06387466192245483\n",
      "Epoch [80/100], Loss: 0.06387537717819214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:02:20,686] Trial 14 finished with value: 24.723457206763666 and parameters: {'learning_rate': 0.08036485768837771, 'hidden_size': 5, 'num_layers': 8, 'batch_size': 64, 'dropout': 0.43890336076828995}. Best is trial 12 with value: 10.857660870896238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.06387543678283691\n",
      "Epoch [20/100], Loss: 0.08965639770030975\n",
      "Epoch [40/100], Loss: 0.08158917725086212\n",
      "Epoch [60/100], Loss: 0.09685514867305756\n",
      "Epoch [80/100], Loss: 0.10563474148511887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:03:43,313] Trial 15 finished with value: 10.178426319494083 and parameters: {'learning_rate': 0.018546802539428205, 'hidden_size': 25, 'num_layers': 8, 'batch_size': 64, 'dropout': 0.48655738052492503}. Best is trial 15 with value: 10.178426319494083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.10653971135616302\n",
      "Epoch [20/100], Loss: 0.05724477022886276\n",
      "Epoch [40/100], Loss: 0.06681285798549652\n",
      "Epoch [60/100], Loss: 0.06581161916255951\n",
      "Epoch [80/100], Loss: 0.06678174436092377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:05:12,118] Trial 16 finished with value: 27.258810419410935 and parameters: {'learning_rate': 0.02350892670264609, 'hidden_size': 30, 'num_layers': 8, 'batch_size': 64, 'dropout': 0.3971104259547732}. Best is trial 15 with value: 10.178426319494083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.06681732833385468\n",
      "Epoch [20/100], Loss: 0.04327904060482979\n",
      "Epoch [40/100], Loss: 0.08567192405462265\n",
      "Epoch [60/100], Loss: 0.06335314363241196\n",
      "Epoch [80/100], Loss: 0.08158881962299347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:06:07,126] Trial 17 finished with value: 24.758842578568167 and parameters: {'learning_rate': 0.09248685575188308, 'hidden_size': 50, 'num_layers': 2, 'batch_size': 64, 'dropout': 0.4973134426404715}. Best is trial 15 with value: 10.178426319494083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0624210461974144\n",
      "Epoch [20/100], Loss: 0.09103534370660782\n",
      "Epoch [40/100], Loss: 0.05351588502526283\n",
      "Epoch [60/100], Loss: 0.054995354264974594\n",
      "Epoch [80/100], Loss: 0.07138160616159439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:07:11,329] Trial 18 finished with value: 30.945495755334942 and parameters: {'learning_rate': 0.016128708043272273, 'hidden_size': 25, 'num_layers': 4, 'batch_size': 64, 'dropout': 0.3954084356426193}. Best is trial 15 with value: 10.178426319494083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.07710012048482895\n",
      "Epoch [20/100], Loss: 0.04724040627479553\n",
      "Epoch [40/100], Loss: 0.04723721742630005\n",
      "Epoch [60/100], Loss: 0.0472370907664299\n",
      "Epoch [80/100], Loss: 0.04911429435014725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:09:46,435] Trial 19 finished with value: 86.02770058998117 and parameters: {'learning_rate': 0.03391730227288369, 'hidden_size': 30, 'num_layers': 9, 'batch_size': 32, 'dropout': 0.29883021358169937}. Best is trial 15 with value: 10.178426319494083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.047839827835559845\n",
      "Epoch [20/100], Loss: 0.03836609050631523\n",
      "Epoch [40/100], Loss: 0.07369405031204224\n",
      "Epoch [60/100], Loss: 0.08335959911346436\n",
      "Epoch [80/100], Loss: 0.08731050044298172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:10:54,324] Trial 20 finished with value: 12.759265790105454 and parameters: {'learning_rate': 0.012152792232769015, 'hidden_size': 20, 'num_layers': 5, 'batch_size': 64, 'dropout': 0.46911758928674513}. Best is trial 15 with value: 10.178426319494083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.05573653429746628\n",
      "Epoch [20/100], Loss: 0.08361807465553284\n",
      "Epoch [40/100], Loss: 0.06269584596157074\n",
      "Epoch [60/100], Loss: 0.05718686804175377\n",
      "Epoch [80/100], Loss: 0.08297432959079742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:12:12,570] Trial 21 finished with value: 9.189601160583814 and parameters: {'learning_rate': 0.008064783050198608, 'hidden_size': 10, 'num_layers': 7, 'batch_size': 64, 'dropout': 0.4594444109038407}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.06929463893175125\n",
      "Epoch [20/100], Loss: 0.12018130719661713\n",
      "Epoch [40/100], Loss: 0.11958955228328705\n",
      "Epoch [60/100], Loss: 0.11955852061510086\n",
      "Epoch [80/100], Loss: 0.11956940591335297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:13:29,923] Trial 22 finished with value: 10.795240808278253 and parameters: {'learning_rate': 0.009458604353316948, 'hidden_size': 10, 'num_layers': 7, 'batch_size': 64, 'dropout': 0.4986362980946092}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.11957070976495743\n",
      "Epoch [20/100], Loss: 0.04683319106698036\n",
      "Epoch [40/100], Loss: 0.06186496093869209\n",
      "Epoch [60/100], Loss: 0.07312685251235962\n",
      "Epoch [80/100], Loss: 0.069434754550457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:14:45,066] Trial 23 finished with value: 9.892630069226673 and parameters: {'learning_rate': 0.010004337919291287, 'hidden_size': 15, 'num_layers': 7, 'batch_size': 64, 'dropout': 0.4607881788350834}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.07813885062932968\n",
      "Epoch [20/100], Loss: 0.06902285665273666\n",
      "Epoch [40/100], Loss: 0.09736047685146332\n",
      "Epoch [60/100], Loss: 0.0959208682179451\n",
      "Epoch [80/100], Loss: 0.0956764966249466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:16:07,658] Trial 24 finished with value: 10.1315829105087 and parameters: {'learning_rate': 0.004358580511797656, 'hidden_size': 20, 'num_layers': 9, 'batch_size': 64, 'dropout': 0.45427870688996963}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.09561676532030106\n",
      "Epoch [20/100], Loss: 0.07525647431612015\n",
      "Epoch [40/100], Loss: 0.08140435069799423\n",
      "Epoch [60/100], Loss: 0.08579450100660324\n",
      "Epoch [80/100], Loss: 0.06521964818239212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:17:30,224] Trial 25 finished with value: 11.68631029439908 and parameters: {'learning_rate': 0.0033705508261851628, 'hidden_size': 15, 'num_layers': 9, 'batch_size': 64, 'dropout': 0.41639785283833936}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.0644519180059433\n",
      "Epoch [20/100], Loss: 0.06450732797384262\n",
      "Epoch [40/100], Loss: 0.05797417461872101\n",
      "Epoch [60/100], Loss: 0.06056022644042969\n",
      "Epoch [80/100], Loss: 0.07379104942083359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:18:52,549] Trial 26 finished with value: 10.48987735021206 and parameters: {'learning_rate': 0.006562409096645486, 'hidden_size': 20, 'num_layers': 9, 'batch_size': 64, 'dropout': 0.4596637989379206}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.07982713729143143\n",
      "Epoch [20/100], Loss: 0.056720905005931854\n",
      "Epoch [40/100], Loss: 0.059986378997564316\n",
      "Epoch [60/100], Loss: 0.030960923060774803\n",
      "Epoch [80/100], Loss: 0.021037118509411812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:20:08,369] Trial 27 finished with value: 77.79897158059165 and parameters: {'learning_rate': 0.0024913666702540433, 'hidden_size': 15, 'num_layers': 7, 'batch_size': 64, 'dropout': 0.41399936326003184}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.01533550675958395\n",
      "Epoch [20/100], Loss: 0.07792073488235474\n",
      "Epoch [40/100], Loss: 0.0907500833272934\n",
      "Epoch [60/100], Loss: 0.11163311451673508\n",
      "Epoch [80/100], Loss: 0.12580886483192444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:20:53,768] Trial 28 finished with value: 11.623465236580365 and parameters: {'learning_rate': 0.010227391073038054, 'hidden_size': 20, 'num_layers': 6, 'batch_size': 128, 'dropout': 0.4623126446094664}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.08894767612218857\n",
      "Epoch [20/100], Loss: 0.04969954118132591\n",
      "Epoch [40/100], Loss: 0.0772918313741684\n",
      "Epoch [60/100], Loss: 0.06242728233337402\n",
      "Epoch [80/100], Loss: 0.05288274586200714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 19:23:33,820] Trial 29 finished with value: 11.467471327781125 and parameters: {'learning_rate': 0.004495488845486523, 'hidden_size': 10, 'num_layers': 9, 'batch_size': 32, 'dropout': 0.43509380552487575}. Best is trial 21 with value: 9.189601160583814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.06689434498548508\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "best_params = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch Forecasting Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"max_split_size_mb:128\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "from pytorch_forecasting import GRU, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder\n",
    "from pytorch_forecasting.metrics import SMAPE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "import warnings\n",
    "# To ignore all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*and is already saved during checkpointing*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*The number of training batches*\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../../data/electricity/df_electricity_processed.csv')\n",
    "train_df = pd.read_csv('../../data/electricity/train_df.csv')\n",
    "test_df = pd.read_csv('../../data/electricity/test_df.csv')\n",
    "X_train_df = pd.read_csv('../../data/electricity/y_train_df.csv')\n",
    "X_test_df = pd.read_csv('../../data/electricity/X_test_df.csv')\n",
    "y_train_df = pd.read_csv('../../data/electricity/y_train_df.csv')\n",
    "y_test_df = pd.read_csv('../../data/electricity/y_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_variable = train_df.drop(columns=['datetime_utc','price_de']).columns\n",
    "target_variable = 'price_de'\n",
    "timestemp_col = 'datetime_utc'\n",
    "step_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.copy()\n",
    "df['datetime_utc'] = pd.to_datetime(df['datetime_utc'])\n",
    "df['datetime_utc'] = (df['datetime_utc'] - df['datetime_utc'].min()).dt.total_seconds() // 3600 + 1 #df_train_val['ds'].max() + 1\n",
    "df['datetime_utc'] = df['datetime_utc'].astype(int)\n",
    "df_train_val = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 24*7\n",
    "max_prediction_length = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"seq_length\": 24 * 7,             # Sequence length\n",
    "    \"target_seq_length\": 24,          # Target sequence length for forecasting\n",
    "    \"input_size\": len(feature_variable), #1,                  # Input size\n",
    "    \"hidden_size\": 50,                # Hidden size of GRU\n",
    "    \"num_layers\": 5,                  # Number of layers in GRU\n",
    "    \"output_size\": len(feature_variable),                 # Output size\n",
    "    \"learning_rate\": 0.005,           # Learning rate\n",
    "    \"epochs\": 500,                    # Number of training epochs\n",
    "    \"batch_size\": 128                 # Batch size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_utc</th>\n",
       "      <th>price_de_lag_336</th>\n",
       "      <th>price_de_avg_24</th>\n",
       "      <th>price_at_lag_24</th>\n",
       "      <th>price_at_avg_24</th>\n",
       "      <th>price_fr_lag_24</th>\n",
       "      <th>price_fr_avg_24</th>\n",
       "      <th>load_de_lag_24</th>\n",
       "      <th>load_de_lag_168</th>\n",
       "      <th>load_at</th>\n",
       "      <th>gen_de</th>\n",
       "      <th>gen_de_lag_168</th>\n",
       "      <th>gen_at</th>\n",
       "      <th>gen_fr</th>\n",
       "      <th>windon_de</th>\n",
       "      <th>solar_de</th>\n",
       "      <th>price_de</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>135.71</td>\n",
       "      <td>143.192083</td>\n",
       "      <td>130.59</td>\n",
       "      <td>145.302083</td>\n",
       "      <td>136.77</td>\n",
       "      <td>142.511250</td>\n",
       "      <td>48193.0200</td>\n",
       "      <td>49161.9775</td>\n",
       "      <td>4868.0</td>\n",
       "      <td>49417.49</td>\n",
       "      <td>50407.76</td>\n",
       "      <td>4079.2</td>\n",
       "      <td>40284.0</td>\n",
       "      <td>16063.7425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.65</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>140.35</td>\n",
       "      <td>141.425000</td>\n",
       "      <td>119.09</td>\n",
       "      <td>144.504167</td>\n",
       "      <td>119.09</td>\n",
       "      <td>140.804167</td>\n",
       "      <td>44770.8675</td>\n",
       "      <td>48136.9350</td>\n",
       "      <td>4378.0</td>\n",
       "      <td>49446.61</td>\n",
       "      <td>49715.33</td>\n",
       "      <td>4027.1</td>\n",
       "      <td>39246.0</td>\n",
       "      <td>16839.0400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.68</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>139.95</td>\n",
       "      <td>138.880833</td>\n",
       "      <td>116.32</td>\n",
       "      <td>143.657500</td>\n",
       "      <td>116.32</td>\n",
       "      <td>138.950417</td>\n",
       "      <td>43981.9450</td>\n",
       "      <td>47600.7900</td>\n",
       "      <td>4829.0</td>\n",
       "      <td>48568.35</td>\n",
       "      <td>49051.50</td>\n",
       "      <td>3933.9</td>\n",
       "      <td>39366.5</td>\n",
       "      <td>17616.8775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.26</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>150.30</td>\n",
       "      <td>135.647500</td>\n",
       "      <td>114.60</td>\n",
       "      <td>142.480000</td>\n",
       "      <td>114.60</td>\n",
       "      <td>136.477083</td>\n",
       "      <td>43422.0775</td>\n",
       "      <td>47753.3075</td>\n",
       "      <td>4773.0</td>\n",
       "      <td>48487.32</td>\n",
       "      <td>49083.27</td>\n",
       "      <td>3766.6</td>\n",
       "      <td>37003.5</td>\n",
       "      <td>17984.3850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>149.51</td>\n",
       "      <td>132.467917</td>\n",
       "      <td>115.07</td>\n",
       "      <td>141.435417</td>\n",
       "      <td>115.07</td>\n",
       "      <td>134.017500</td>\n",
       "      <td>43581.7450</td>\n",
       "      <td>49360.8175</td>\n",
       "      <td>4833.0</td>\n",
       "      <td>49072.56</td>\n",
       "      <td>50384.18</td>\n",
       "      <td>3585.8</td>\n",
       "      <td>34949.5</td>\n",
       "      <td>18902.0375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.76</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8993</th>\n",
       "      <td>8996</td>\n",
       "      <td>120.89</td>\n",
       "      <td>90.798333</td>\n",
       "      <td>112.41</td>\n",
       "      <td>95.982917</td>\n",
       "      <td>112.22</td>\n",
       "      <td>90.937500</td>\n",
       "      <td>64363.1600</td>\n",
       "      <td>62435.3950</td>\n",
       "      <td>7798.0</td>\n",
       "      <td>54701.73</td>\n",
       "      <td>60625.63</td>\n",
       "      <td>7268.6</td>\n",
       "      <td>63410.5</td>\n",
       "      <td>15818.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.58</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>8997</td>\n",
       "      <td>100.05</td>\n",
       "      <td>91.503333</td>\n",
       "      <td>99.15</td>\n",
       "      <td>96.557083</td>\n",
       "      <td>103.63</td>\n",
       "      <td>91.325000</td>\n",
       "      <td>62330.2025</td>\n",
       "      <td>59991.6850</td>\n",
       "      <td>7289.0</td>\n",
       "      <td>51345.73</td>\n",
       "      <td>60074.36</td>\n",
       "      <td>6770.3</td>\n",
       "      <td>61559.0</td>\n",
       "      <td>15185.0900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.93</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>8998</td>\n",
       "      <td>96.84</td>\n",
       "      <td>92.433333</td>\n",
       "      <td>85.54</td>\n",
       "      <td>97.372083</td>\n",
       "      <td>92.50</td>\n",
       "      <td>91.850000</td>\n",
       "      <td>58638.3150</td>\n",
       "      <td>56167.5975</td>\n",
       "      <td>6780.0</td>\n",
       "      <td>47738.81</td>\n",
       "      <td>58340.22</td>\n",
       "      <td>6173.9</td>\n",
       "      <td>59780.5</td>\n",
       "      <td>14189.9350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.10</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>8999</td>\n",
       "      <td>93.70</td>\n",
       "      <td>93.263750</td>\n",
       "      <td>84.04</td>\n",
       "      <td>98.202500</td>\n",
       "      <td>84.04</td>\n",
       "      <td>92.680417</td>\n",
       "      <td>55156.1275</td>\n",
       "      <td>52589.0625</td>\n",
       "      <td>6568.0</td>\n",
       "      <td>45213.73</td>\n",
       "      <td>56945.46</td>\n",
       "      <td>5898.0</td>\n",
       "      <td>58930.5</td>\n",
       "      <td>13123.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.97</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>9000</td>\n",
       "      <td>84.60</td>\n",
       "      <td>94.048750</td>\n",
       "      <td>74.36</td>\n",
       "      <td>98.987500</td>\n",
       "      <td>74.36</td>\n",
       "      <td>93.465417</td>\n",
       "      <td>51880.5625</td>\n",
       "      <td>49415.5050</td>\n",
       "      <td>6097.0</td>\n",
       "      <td>42545.78</td>\n",
       "      <td>56195.82</td>\n",
       "      <td>5189.3</td>\n",
       "      <td>57284.0</td>\n",
       "      <td>12409.1350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.20</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8998 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime_utc  price_de_lag_336  price_de_avg_24  price_at_lag_24  \\\n",
       "0                1            135.71       143.192083           130.59   \n",
       "1                2            140.35       141.425000           119.09   \n",
       "2                3            139.95       138.880833           116.32   \n",
       "3                4            150.30       135.647500           114.60   \n",
       "4                5            149.51       132.467917           115.07   \n",
       "...            ...               ...              ...              ...   \n",
       "8993          8996            120.89        90.798333           112.41   \n",
       "8994          8997            100.05        91.503333            99.15   \n",
       "8995          8998             96.84        92.433333            85.54   \n",
       "8996          8999             93.70        93.263750            84.04   \n",
       "8997          9000             84.60        94.048750            74.36   \n",
       "\n",
       "      price_at_avg_24  price_fr_lag_24  price_fr_avg_24  load_de_lag_24  \\\n",
       "0          145.302083           136.77       142.511250      48193.0200   \n",
       "1          144.504167           119.09       140.804167      44770.8675   \n",
       "2          143.657500           116.32       138.950417      43981.9450   \n",
       "3          142.480000           114.60       136.477083      43422.0775   \n",
       "4          141.435417           115.07       134.017500      43581.7450   \n",
       "...               ...              ...              ...             ...   \n",
       "8993        95.982917           112.22        90.937500      64363.1600   \n",
       "8994        96.557083           103.63        91.325000      62330.2025   \n",
       "8995        97.372083            92.50        91.850000      58638.3150   \n",
       "8996        98.202500            84.04        92.680417      55156.1275   \n",
       "8997        98.987500            74.36        93.465417      51880.5625   \n",
       "\n",
       "      load_de_lag_168  load_at    gen_de  gen_de_lag_168  gen_at   gen_fr  \\\n",
       "0          49161.9775   4868.0  49417.49        50407.76  4079.2  40284.0   \n",
       "1          48136.9350   4378.0  49446.61        49715.33  4027.1  39246.0   \n",
       "2          47600.7900   4829.0  48568.35        49051.50  3933.9  39366.5   \n",
       "3          47753.3075   4773.0  48487.32        49083.27  3766.6  37003.5   \n",
       "4          49360.8175   4833.0  49072.56        50384.18  3585.8  34949.5   \n",
       "...               ...      ...       ...             ...     ...      ...   \n",
       "8993       62435.3950   7798.0  54701.73        60625.63  7268.6  63410.5   \n",
       "8994       59991.6850   7289.0  51345.73        60074.36  6770.3  61559.0   \n",
       "8995       56167.5975   6780.0  47738.81        58340.22  6173.9  59780.5   \n",
       "8996       52589.0625   6568.0  45213.73        56945.46  5898.0  58930.5   \n",
       "8997       49415.5050   6097.0  42545.78        56195.82  5189.3  57284.0   \n",
       "\n",
       "       windon_de  solar_de  price_de unique_id  \n",
       "0     16063.7425       0.0     80.65        H1  \n",
       "1     16839.0400       0.0     76.68        H1  \n",
       "2     17616.8775       0.0     55.26        H1  \n",
       "3     17984.3850       0.0     37.00        H1  \n",
       "4     18902.0375       0.0     38.76        H1  \n",
       "...          ...       ...       ...       ...  \n",
       "8993  15818.6625       0.0    123.58        H1  \n",
       "8994  15185.0900       0.0    112.93        H1  \n",
       "8995  14189.9350       0.0    105.10        H1  \n",
       "8996  13123.5375       0.0    103.97        H1  \n",
       "8997  12409.1350       0.0     93.20        H1  \n",
       "\n",
       "[8998 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_val['unique_id'] = 'H1'\n",
    "df_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    df_train_val.iloc[:-max_prediction_length],\n",
    "    time_idx=\"datetime_utc\",\n",
    "    target=\"price_de\",\n",
    "    # time_varying_unknown_reals = feature_variable,\n",
    "    group_ids=['unique_id'],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_encoder_length=min_encoder_length,\n",
    "    # min_encoder_length=max_encoder_length // 2,\n",
    "    # min_encoder_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    # min_prediction_length=max_prediction_length // 2,\n",
    "    # min_prediction_length=1,\n",
    "    # time_varying_known_reals=['y_arima', 'y_theta', 'y_xgb', 'y_gru', 'y_lstm'],  # Base model forecasts\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"unique_id\"], transformation=\"softplus\"\n",
    "    ),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(training, df_train_val, predict=True, stop_randomization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(validation, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-5, patience=50, verbose=False, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        gru_out, _ = self.gru(x, h0)\n",
    "        out = self.fc(gru_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator=\"gpu\",\n",
    "        gradient_clip_val=0.1,\n",
    "        # limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "        # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "        callbacks=[early_stop_callback],\n",
    "        logger=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_checkpointing=False\n",
    "    )\n",
    "\n",
    "\n",
    "# tft = GRU.from_dataset(\n",
    "#     training,\n",
    "#     # not meaningful for finding the learning rate but otherwise very important\n",
    "#     learning_rate=0.03,\n",
    "#     hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "#     # number of attention heads. Set to up to 4 for large datasets\n",
    "#     attention_head_size=1,\n",
    "#     dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "#     hidden_continuous_size=8,  # set to <= hidden_size\n",
    "#     loss=SMAPE(),\n",
    "#     optimizer=\"Ranger\"\n",
    "#     # reduce learning rate if no improvement in validation loss after x epochs\n",
    "#     # reduce_on_plateau_patience=1000,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                # X_train, \n",
    "                # y_train, \n",
    "                batch_size,\n",
    "                epochs):\n",
    "    \n",
    "    # dataset = TensorDataset(X_train, y_train)\n",
    "    data_loader = train_dataloader\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (sequences, targets) in enumerate(data_loader):\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(sequences)\n",
    "            loss = criterion(pred, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    # generating forecasts\n",
    "    model.eval()\n",
    "    last_sequence = X_train[-1:].to(device) # [1, 168, 16]\n",
    "    # with torch.no_grad():\n",
    "    #     forecast_seq = model(last_sequence) \n",
    "\n",
    "\n",
    "    forecast_seq = torch.Tensor().to(device)\n",
    "    \n",
    "    for _ in range(hyperparameters[\"target_seq_length\"]):\n",
    "        with torch.no_grad():\n",
    "            next_step_forecast = model(last_sequence) # [1, 16]\n",
    "            # print(next_step_forecast.size()) # [1, 16]\n",
    "            # print(next_step_forecast[:, -1:].size()) # [1, 1]\n",
    "            # print(next_step_forecast.unsqueeze(-1).size()) # [1, 16, 1]\n",
    "            # print(next_step_forecast.unsqueeze(1).size()) # [1, 1, 16]\n",
    "            # break\n",
    "            # forecast_seq = torch.cat((forecast_seq, next_step_forecast[:, -1:]), dim=1)\n",
    "            forecast_seq = torch.cat((forecast_seq, next_step_forecast), dim=0) # [1, 16, 1]\n",
    "            # print(forecast_seq.size())\n",
    "            # break\n",
    "            last_sequence = torch.cat((last_sequence[:, 1:, :], next_step_forecast.unsqueeze(1)), dim=1)\n",
    "    \n",
    "    return model, forecast_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m all_forecast_seq_descaled \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# X_train = torch.from_numpy(sequences_dict['X'].astype(np.float32))#.unsqueeze(-1)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# y_train = torch.from_numpy(sequences_dict['y'].astype(np.float32)).unsqueeze(1)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGRU_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_layers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'dropout'"
     ]
    }
   ],
   "source": [
    "# y_hat_df_gru = test_data.copy().rename(columns={'y' : 'y_hat'})\n",
    "# y_hat_df_gru['y_hat'] = pd.Series(dtype='float64')\n",
    "\n",
    "all_forecast_seq_descaled = []\n",
    "\n",
    "# X_train = torch.from_numpy(sequences_dict['X'].astype(np.float32))#.unsqueeze(-1)\n",
    "# y_train = torch.from_numpy(sequences_dict['y'].astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "model = GRU_Model(hyperparameters['input_size'], hyperparameters['hidden_size'], hyperparameters['num_layers'], hyperparameters['output_size'])\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = smape_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['learning_rate'])\n",
    "\n",
    "model_gru, forecast_seq = train_model(model,\n",
    "                                    criterion=criterion,\n",
    "                                    optimizer=optimizer,\n",
    "                                    # X_train=X_train,\n",
    "                                    # y_train=y_train,\n",
    "                                    batch_size=hyperparameters['batch_size'],\n",
    "                                    epochs=hyperparameters['epochs'])\n",
    "\n",
    "# forecast_seq_descaled = sequences_dict['scaler'].inverse_transform(forecast_seq.cpu().numpy())\n",
    "# all_forecast_seq_descaled = np.hstack(all_forecast_seq_descaled, forecast_seq_descaled)\n",
    "# all_forecast_seq_descaled.append(forecast_seq_descaled)\n",
    "\n",
    "# all_forecast_seq_descaled = np.hstack(all_forecast_seq_descaled)\n",
    "\n",
    "# y_hat_df_gru['y_hat'] = all_forecast_seq_descaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU_Model(hyperparameters['input_size'], hyperparameters['hidden_size'], hyperparameters['num_layers'], hyperparameters['output_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `ABCMeta`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    506\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m     ckpt_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    511\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Runs the full optimization routine.\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m \n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_unwrap_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    540\u001b[0m     _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\compile.py:132\u001b[0m, in \u001b[0;36m_maybe_unwrap_optimized\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m    131\u001b[0m _check_mixed_imports(model)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `ABCMeta`"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    GRU,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sonng\\anaconda3\\envs\\tsff_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsff_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
